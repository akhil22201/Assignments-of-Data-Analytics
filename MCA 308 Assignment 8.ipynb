{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c0a514-c41e-4f32-9a06-90c72bf085dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "[X0 < 7.444]\n",
      "  [X0 < 2.771]\n",
      "    [0]\n",
      "    [X0 < 2.771]\n",
      "      [0]\n",
      "      [0]\n",
      "  [X0 < 7.497]\n",
      "    [1]\n",
      "    [X0 < 7.497]\n",
      "      [1]\n",
      "      [1]\n",
      "\n",
      "Predictions: [1, 0]\n",
      "Actual: [1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to calculate Gini Index\n",
    "def gini_index(groups, classes):\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini\n",
    "\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    best_index, best_value, best_score, best_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0]) - 1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < best_score:\n",
    "                best_index, best_value, best_score, best_groups = index, row[index], gini, groups\n",
    "    return {'index': best_index, 'value': best_value, 'groups': best_groups}\n",
    "\n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth + 1)\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth + 1)\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "# Function to print the tree\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' % ((depth*'  ', node['index'], node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*'  ', node)))\n",
    "\n",
    "# CART Algorithm\n",
    "def decision_tree(train, test, max_depth, min_size):\n",
    "    tree = build_tree(train, max_depth, min_size)\n",
    "    print(\"Decision Tree:\")\n",
    "    print_tree(tree)\n",
    "    predictions = []\n",
    "    for row in test:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "# --- Example dataset ---\n",
    "dataset = [\n",
    "    [2.771, 1.784, 0],\n",
    "    [1.728, 1.169, 0],\n",
    "    [3.678, 2.812, 0],\n",
    "    [3.961, 2.619, 0],\n",
    "    [2.999, 2.209, 0],\n",
    "    [7.497, 3.162, 1],\n",
    "    [9.002, 3.339, 1],\n",
    "    [7.444, 0.476, 1],\n",
    "    [10.124, 3.234, 1],\n",
    "    [6.642, 3.319, 1]\n",
    "]\n",
    "\n",
    "# Split dataset into training and testing\n",
    "train = dataset[:8]\n",
    "test = dataset[8:]\n",
    "\n",
    "# Run CART decision tree\n",
    "predictions = decision_tree(train, test, max_depth=3, min_size=1)\n",
    "print(\"\\nPredictions:\", predictions)\n",
    "print(\"Actual:\", [row[-1] for row in test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c03635b-f509-4259-9bd7-8ab96ae40323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature: Outlook\n",
      "Rule: {'Overcast': 'Yes', 'Rainy': 'Yes', 'Sunny': 'No'}\n",
      "Errors: 1\n",
      "\n",
      "Feature: Temperature\n",
      "Rule: {'Cool': 'Yes', 'Hot': 'No', 'Mild': 'No'}\n",
      "Errors: 3\n",
      "\n",
      "Feature: Humidity\n",
      "Rule: {'High': 'No', 'Normal': 'Yes'}\n",
      "Errors: 3\n",
      "\n",
      "Feature: Windy\n",
      "Rule: {False: 'Yes', True: 'No'}\n",
      "Errors: 3\n",
      "\n",
      "âœ… Best Feature: Outlook\n",
      "ðŸ“˜ Final Rule: {'Overcast': 'Yes', 'Rainy': 'Yes', 'Sunny': 'No'}\n",
      "Total Errors: 1\n",
      "\n",
      "Final Predictions:\n",
      "    Outlook Temperature Humidity  Windy Play Predicted\n",
      "0     Sunny         Hot     High  False   No        No\n",
      "1     Sunny         Hot     High   True   No        No\n",
      "2  Overcast         Hot     High  False  Yes       Yes\n",
      "3     Rainy        Mild     High  False  Yes       Yes\n",
      "4     Rainy        Cool   Normal  False  Yes       Yes\n",
      "5     Rainy        Cool   Normal   True   No       Yes\n",
      "6  Overcast        Cool   Normal   True  Yes       Yes\n",
      "7     Sunny        Mild     High  False   No        No\n"
     ]
    }
   ],
   "source": [
    "# 2. Implement rule-based classification using OneR algorithm. \n",
    "import pandas as pd\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy', 'Rainy', 'Overcast', 'Sunny'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High'],\n",
    "    'Windy': [False, True, False, False, False, True, True, False],\n",
    "    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to implement OneR\n",
    "def oneR(df, target):\n",
    "    features = df.columns.drop(target)\n",
    "    best_feature = None\n",
    "    min_error = float('inf')\n",
    "    best_rule = {}\n",
    "\n",
    "    for feature in features:\n",
    "        # Create rule for this feature\n",
    "        rule = {}\n",
    "        for value, subset in df.groupby(feature):\n",
    "            # Most common class for this feature value\n",
    "            most_common = subset[target].mode()[0]\n",
    "            rule[value] = most_common\n",
    "        \n",
    "        # Calculate error for this feature\n",
    "        predictions = df[feature].map(rule)\n",
    "        error = sum(predictions != df[target])\n",
    "        \n",
    "        print(f\"\\nFeature: {feature}\")\n",
    "        print(\"Rule:\", rule)\n",
    "        print(\"Errors:\", error)\n",
    "        \n",
    "        # Check if this feature is better\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            best_feature = feature\n",
    "            best_rule = rule\n",
    "\n",
    "    print(\"\\n Best Feature:\", best_feature)\n",
    "    print(\" Final Rule:\", best_rule)\n",
    "    print(\"Total Errors:\", min_error)\n",
    "    return best_feature, best_rule\n",
    "\n",
    "# Run OneR Algorithm\n",
    "best_feature, best_rule = oneR(df, 'Play')\n",
    "\n",
    "# Predicting using the rule\n",
    "def predict(row):\n",
    "    value = row[best_feature]\n",
    "    return best_rule.get(value, 'Unknown')\n",
    "\n",
    "df['Predicted'] = df.apply(predict, axis=1)\n",
    "print(\"\\nFinal Predictions:\")\n",
    "print(df[['Outlook', 'Temperature', 'Humidity', 'Windy', 'Play', 'Predicted']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
